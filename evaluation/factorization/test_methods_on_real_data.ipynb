{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Set number of cores for parallel computation\n",
    "# For just reading output files and creating summary, use 1 kernel\n",
    "KERNEL = 20\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys,os\n",
    "import random\n",
    "import copyx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from utils.eval import find_best_matches, generate_exprs\n",
    "\n",
    "from methods import NMF, PCA, sparse_PCA, moCluster, MOFA2\n",
    "\n",
    "from methods.utils import interpret_results, resultsHandler\n",
    "\n",
    "from pathlib import Path\n",
    "import multiprocessing as mp\n",
    "\n",
    "from utils.eval import find_best_matches, make_known_groups, find_best_matching_biclusters\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_ref_groups(subtypes, annotation,exprs):\n",
    "    # prepared a dict of subtype classifications {\"class1\":{\"subt1\":[],\"subt2\":[]},\"class2\":{\"subtA\":[],\"subtB\":[]}}\n",
    "    all_samples = set(exprs.columns.values)\n",
    "    pam50 = make_known_groups(subtypes, exprs,target_col = \"PAM50\",verbose=False)\n",
    "    lum = {}\n",
    "    lum[\"Luminal\"] = pam50[\"LumA\"].union(pam50[\"LumB\"])\n",
    "    scmod2 = make_known_groups(subtypes, exprs,target_col = 'SCMOD2',verbose=False)\n",
    "    claudin = {} \n",
    "    claudin[\"Claudin-low\"] = set(subtypes.loc[subtypes['claudin_low']==1,:].index.values).intersection(all_samples)\n",
    "    \n",
    "    ihc = {}\n",
    "    for x in [\"IHC_HER2\",\"IHC_ER\",\"IHC_PR\"]:\n",
    "        ihc[x] = set(annotation.loc[annotation[x]==\"Positive\",:].index.values)\n",
    "    ihc[\"IHC_TNBC\"] = set(annotation.loc[annotation[\"IHC_TNBC\"]==1,:].index.values)\n",
    "    \n",
    "    known_groups = {\"PAM50\":pam50,\"Luminal\":lum,\"Claudin-low\":claudin,\"SCMOD2\":scmod2,\"IHC\":ihc}\n",
    "    \n",
    "    freqs = {}\n",
    "    N =  exprs.shape[1]\n",
    "    for classification in known_groups.keys():\n",
    "        for group in known_groups[classification].keys():\n",
    "            n = len(known_groups[classification][group])\n",
    "            freqs[group] = n/N\n",
    "            \n",
    "    return known_groups, freqs\n",
    "\n",
    "def calculate_perfromance(results, known_groups, freqs, all_samples,\n",
    "                          classifications={\"Intrinsic\":[\"Luminal\",\"Basal\",\"Her2\",\"Normal\",\"Claudin-low\"]}):\n",
    "    # finds best matches for each subtype, calcuates J per subtype and overall performance\n",
    "    N = len(all_samples)\n",
    "    best_matches = []\n",
    "    \n",
    "    for classification in known_groups.keys():\n",
    "        bm = find_best_matches(results,known_groups[classification],all_samples,FDR=0.05,verbose = False)\n",
    "        best_matches.append(bm)\n",
    "            \n",
    "    best_matches = pd.concat(best_matches, axis=0)\n",
    "    best_matches = best_matches[\"J\"].to_dict()\n",
    "    \n",
    "    for cl_name in classifications.keys():\n",
    "        overall_performance = 0\n",
    "        norm_factor = 0\n",
    "        for group in classifications[cl_name]:\n",
    "            overall_performance += best_matches[group]*freqs[group]\n",
    "            norm_factor +=freqs[group]\n",
    "        overall_performance = overall_performance/norm_factor \n",
    "        best_matches[\"overall_performance_\"+cl_name] = overall_performance\n",
    "    return best_matches\n",
    "\n",
    "def compare_gene_clusters(tcga_result,metabric_result, N):\n",
    "    # N - total number of genes\n",
    "    # finds best matched TCGA -> METABRIC and METABRIC -> TCGA\n",
    "    # calculates % of matched clusterst, number of genes in matched cluster, \n",
    "    # and the average J index for best matches \n",
    "    bm = find_best_matching_biclusters(tcga_result,metabric_result, N)\n",
    "    bm = bm.dropna()\n",
    "    bm2 = find_best_matching_biclusters(metabric_result, tcga_result, N)\n",
    "    bm2 = bm2.dropna()\n",
    "    \n",
    "    bm = bm.loc[bm[\"n_shared\"]>1,:].sort_values(by=\"n_shared\",ascending = False)\n",
    "    bm2 = bm2.loc[bm2[\"n_shared\"]>1,:].sort_values(by=\"n_shared\",ascending = False)\n",
    "    \n",
    "    \n",
    "    clust_similarity = {}\n",
    "    # number of biclusters \n",
    "    clust_similarity[\"n_1\"] = tcga_result.shape[0]\n",
    "    clust_similarity[\"n_2\"] = metabric_result.shape[0]\n",
    "    #print(\"% matched biclusters:\",bm.shape[0]/tcga_result.shape[0],bm2.shape[0]/metabric_result.shape[0])\n",
    "    clust_similarity[\"percent_matched_1\"] = bm.shape[0]/tcga_result.shape[0]\n",
    "    clust_similarity[\"percent_matched_2\"] = bm2.shape[0]/metabric_result.shape[0]\n",
    "    #print(\"n matched genes:\",bm.loc[:,\"n_shared\"].sum(),bm2.loc[:,\"n_shared\"].sum())\n",
    "    clust_similarity[\"n_shared_genes_1\"] = bm.loc[:,\"n_shared\"].sum()\n",
    "    clust_similarity[\"n_shared_genes_2\"] = bm2.loc[:,\"n_shared\"].sum()\n",
    "    #print(\"avg. J:\",bm.loc[:,\"J\"].mean(),bm2.loc[:,\"J\"].mean())\n",
    "    clust_similarity[\"avg_bm_J_1\"] = bm.loc[:,\"J\"].mean()\n",
    "    clust_similarity[\"avg_bm_J_2\"] = bm2.loc[:,\"J\"].mean()\n",
    "    \n",
    "    \n",
    "    return clust_similarity, bm, bm2\n",
    "\n",
    "\n",
    "classifications={\"Intrinsic\":[\"Luminal\",\"Basal\",\"Her2\",\"Normal\",\"Claudin-low\"],\n",
    "                \"SCMOD2\":[\"ER-/HER2-\",\"ER+/HER2- Low Prolif\",\"ER+/HER2- High Prolif\",\"HER2+\"],\n",
    "                \"IHC\":[\"IHC_TNBC\",\"IHC_ER\",\"IHC_HER2\",\"IHC_PR\"]}\n",
    "\n",
    "file_metabric_annotation = '/local/DESMOND2_data/v6/preprocessed_v6/METABRIC_1904.annotation_v6.tsv'\n",
    "file_metabric_expression = '/local/DESMOND2_data/v6/preprocessed_v6/METABRIC_1904_17Kgenes.log2_exprs_z_v6.tsv'\n",
    "file_metabric_subtypes = '/local/DESMOND2_data/v6/preprocessed_v6/METABRIC_1904_17Kgenes.subtypes_and_signatures_v6.tsv'\n",
    "file_tcga_annotation = '/local/DESMOND2_data/v6/preprocessed_v6/TCGA-BRCA_1079.Xena_TCGA_PanCan.annotation_v6.tsv'\n",
    "file_tcga_expression = '/local/DESMOND2_data/v6/preprocessed_v6/TCGA-BRCA_1079_17Kgenes.Xena_TCGA_PanCan.log2_exprs_z_v6.tsv'\n",
    "file_tcga_subtypes = '/local/DESMOND2_data/v6/preprocessed_v6/TCGA-BRCA_1079_17Kgenes.Xena_TCGA_PanCan.subtypes_and_signatures_v6.tsv'\n",
    "file_gene_mapping = '/local/DESMOND2_data/v6/preprocessed_v6/gene_id_mapping.tsv'\n",
    "\n",
    "# out_dir = '/home/hartung/data/preprocessed_v6/results's\n",
    "out_dir = '/home/bba1401/data/unpast_real'\n",
    "\n",
    "basename_t = \"TCGA\"\n",
    "basename_m = \"METABRIC\" \n",
    "\n",
    "\n",
    "m_subtypes = pd.read_csv(file_metabric_subtypes,sep = \"\\t\",index_col=0)\n",
    "m_annotation = pd.read_csv(file_metabric_annotation,sep = \"\\t\",index_col=0)\n",
    "\n",
    "t_subtypes = pd.read_csv(file_tcga_subtypes,sep = \"\\t\",index_col=0)\n",
    "t_annotation = pd.read_csv(file_tcga_annotation,sep = \"\\t\",index_col=0)\n",
    "\n",
    "\n",
    "exprs_t= pd.read_csv(file_tcga_expression,sep = \"\\t\",index_col=0)\n",
    "exprs_t[exprs_t>3] = 3\n",
    "exprs_t[exprs_t<-3] = -3\n",
    "\n",
    "exprs_m= pd.read_csv(file_metabric_expression,sep = \"\\t\",index_col=0)\n",
    "exprs_m[exprs_m>3] = 3\n",
    "exprs_m[exprs_m<-3] = -3\n",
    "\n",
    "known_groups_t, freqs_t = make_ref_groups(t_subtypes, t_annotation,exprs_t)\n",
    "known_groups_m, freqs_m = make_ref_groups(m_subtypes, m_annotation,exprs_m)\n",
    "\n",
    "with open('mocluster_log.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        \n",
    "        METHODS = [NMF, sparse_PCA] # [NMF, sparse_PCA, moCluster, MOFA2]\n",
    "        for METHOD in METHODS:\n",
    "            method_name = METHOD.__name__.split('.')[-1]\n",
    "\n",
    "            #### Preparation\n",
    "            # METABRIC\n",
    "            file_path_m = file_metabric_expression\n",
    "            output_path_m = os.path.join(out_dir, basename_m, method_name)\n",
    "            ground_truth_file_m = file_metabric_annotation\n",
    "            combinations_m = METHOD.generate_arg_list(file_path_m, output_path_m, ground_truth_file_m)\n",
    "            # TCGA\n",
    "            file_path_t = file_tcga_expression\n",
    "            output_path_t = os.path.join(out_dir, basename_t, method_name)\n",
    "            ground_truth_file_t = file_tcga_annotation\n",
    "            combinations_t = METHOD.generate_arg_list(file_path_t, output_path_t, ground_truth_file_t)\n",
    "\n",
    "\n",
    "            #### Compute in parallel\n",
    "            # Option to compute the results in parallel, methods will store results\n",
    "            # Follow up with executing the 'Run' below to read existing results and evaluate\n",
    "            if KERNEL > 1:\n",
    "                with mp.Pool(KERNEL) as pool:\n",
    "                    pool.map(METHOD.run_real, combinations_m + combinations_t)\n",
    "\n",
    "\n",
    "            #### Run\n",
    "            # Methods will compute results or read existing results\n",
    "            # sanity check\n",
    "            assert len(combinations_m) == len(combinations_t)\n",
    "            subt_t = []\n",
    "            subt_m = []\n",
    "            clustering_similarities = []\n",
    "            for comb_m, comb_t in zip(combinations_m, combinations_t):\n",
    "                result_m, runtime_m = METHOD.run_real(comb_m)\n",
    "                result_t, runtime_t = METHOD.run_real(comb_t)\n",
    "\n",
    "                try:\n",
    "                    performance_m = calculate_perfromance(result_m, known_groups_m,\n",
    "                                                          freqs_m, set(exprs_m.columns.values),\n",
    "                                                          classifications=classifications)\n",
    "                    performance_m.update({'parameters': comb_m['output_path'], 'run': comb_m['random_state']})\n",
    "                    performance_m['time'] = runtime_m\n",
    "                except ZeroDivisionError:\n",
    "                    performance_m = {}\n",
    "                subt_m.append(performance_m)\n",
    "\n",
    "                try:\n",
    "                    performance_t = calculate_perfromance(result_t, known_groups_t,\n",
    "                                                          freqs_t, set(exprs_t.columns.values),\n",
    "                                                          classifications=classifications)\n",
    "                    performance_t.update({'parameters': comb_t['output_path'], 'run': comb_t['random_state']})\n",
    "                    performance_t['time'] = runtime_t\n",
    "                except ZeroDivisionError:\n",
    "                    performance_t = {}\n",
    "                subt_t.append(performance_t)\n",
    "\n",
    "\n",
    "            # save results\n",
    "            pd.DataFrame.from_records(subt_m).to_csv(os.path.join(out_dir, basename_m, method_name, f'{method_name}_METABRIC.tsv'), sep=\"\\t\")    \n",
    "            pd.DataFrame.from_records(subt_t).to_csv(os.path.join(out_dir, basename_t, method_name, f'{method_name}_TCGA.tsv'), sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encore2",
   "language": "python",
   "name": "encore2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "40c10eda78a8dc683b7bfd2c6e2f577a5d62e25eac6af3276076792a7b2f5336"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
