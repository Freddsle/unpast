{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_name NMF\n",
      "{'k': '8', 'init': 'nndsvda', 'tol': '0.0001', 'transposed': 'False', 'alpha_W': '-0.1', 'alpha_H': '0.0', 'shuffle': 'False', 'solver': 'cd', 'beta_loss': 'frobenius', 'max_iter': '1000'}\n",
      "method_name moCluster\n",
      "{'n_dimensions': '5', 'n_cluster': '13', 'solver': 'svd', 'center': 'True', 'method': 'globalScore', 'option': 'uniform', 'scale': 'False', 'k': '1'}\n",
      "method_name MOFA2\n",
      "{'n_factors': '12', 'n_cluster': '9', 'ard_weights': 'True', 'ard_factors': 'False', 'likelihood': 'gaussian', 'spikeslab_weights': 'True', 'spikeslab_factors': 'False'}\n",
      "method_name iClusterPlus\n",
      "{'lambda_n': '10', 'n_cluster': '12', 'lambda_scale': '1', 'iter_max': '20', 'eps': '0.0001', 'type': 'gaussian', 'burnin_n': '200', 'draw_n': '200', 'sdev': '0.05'}\n",
      "method_name sparse_PCA\n",
      "{'n_components': '9', 'alpha': '1', 'ridge_alpha': '0.001', 'max_iter': '1000', 'method': 'cd', 'tol': '1e-08'}\n"
     ]
    }
   ],
   "source": [
    "# best average rank in BRCA\n",
    "\n",
    "import pandas as pd\n",
    "from methods import NMF, sparse_PCA, moCluster, MOFA2, iClusterPlus\n",
    "\n",
    "for method in [NMF, moCluster, MOFA2, iClusterPlus, sparse_PCA]:\n",
    "    method_name = method.__name__.split('.')[-1]\n",
    "    print('method_name', method_name)\n",
    "    \n",
    "    df_meta = pd.read_csv(f'/cosybio/project/hartung/unpast/unpast_real/{method_name}_METABRIC.tsv', sep='\\t', index_col=0)\n",
    "    df_tcga = pd.read_csv(f'/cosybio/project/hartung/unpast/unpast_real/{method_name}_TCGA.tsv', sep='\\t', index_col=0)\n",
    "    \n",
    "    df_meta = df_meta.dropna(subset='parameters')\n",
    "    df_tcga = df_tcga.dropna(subset='parameters')\n",
    "    \n",
    "    # remove random state from params\n",
    "    df_meta['parameters'] = df_meta['parameters'].map(lambda x: ';'.join([y for y in x.split(';') if not y.startswith('random_state=')]))\n",
    "    df_tcga['parameters'] = df_tcga['parameters'].map(lambda x: ';'.join([y for y in x.split(';') if not y.startswith('random_state=')]))\n",
    "    \n",
    "    # merge permutations\n",
    "    df_meta = df_meta.groupby('parameters').mean()\n",
    "    df_tcga = df_tcga.groupby('parameters').mean()\n",
    "    \n",
    "    df_meta = df_meta.sort_values('PAM50', ascending=False)\n",
    "    df_meta['rank'] = list(range(len(df_meta.index)))\n",
    "    \n",
    "    df_tcga = df_tcga.sort_values('PAM50', ascending=False)\n",
    "    df_tcga['rank'] = list(range(len(df_tcga.index)))\n",
    "    \n",
    "    df = pd.concat([df_tcga, df_meta]).groupby('parameters').sum()\n",
    "    \n",
    "    params = df.sort_values('rank', ascending=True).index[0]\n",
    "    d = {y[0]: y[1] for y in [x.split('=') for x in params.split(';') if len(x)]}\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_name NMF\n",
      "TCGA\n",
      "{'k': 8, 'init': 'nndsvda', 'tol': 0.0001, 'transposed': False, 'alpha_W': -0.1, 'alpha_H': 0.0, 'shuffle': False, 'solver': 'cd', 'beta_loss': 'frobenius', 'max_iter': 1000}\n",
      "METABRIC\n",
      "{'k': 3, 'init': 'nndsvda', 'tol': 0.0001, 'transposed': False, 'alpha_W': -0.1, 'alpha_H': 0.0, 'shuffle': False, 'solver': 'cd', 'beta_loss': 'frobenius', 'max_iter': 200}\n",
      "method_name moCluster\n",
      "TCGA\n",
      "{'n_dimensions': 4, 'n_cluster': 10, 'solver': 'fast', 'center': True, 'method': 'globalScore', 'option': 'inertia', 'scale': False, 'k': 1}\n",
      "METABRIC\n",
      "{'n_dimensions': 15, 'n_cluster': 20, 'solver': 'fast', 'center': True, 'method': 'globalScore', 'option': 'lambda1', 'scale': False, 'k': 0.1}\n",
      "method_name MOFA2\n",
      "TCGA\n",
      "{'n_factors': 2, 'n_cluster': 7, 'ard_weights': True, 'ard_factors': False, 'likelihood': 'gaussian', 'spikeslab_weights': True, 'spikeslab_factors': False}\n",
      "METABRIC\n",
      "{'n_factors': 19, 'n_cluster': 11, 'ard_weights': True, 'ard_factors': False, 'likelihood': 'gaussian', 'spikeslab_weights': True, 'spikeslab_factors': False}\n",
      "method_name iClusterPlus\n",
      "TCGA\n",
      "{'lambda_n': 5, 'n_cluster': 11, 'lambda_scale': 1, 'iter_max': 20, 'eps': 0.0001, 'type': 'gaussian', 'burnin_n': 200, 'draw_n': 200, 'sdev': 0.05}\n",
      "METABRIC\n",
      "{'lambda_n': 10, 'n_cluster': 13, 'lambda_scale': 1, 'iter_max': 20, 'eps': 0.0001, 'type': 'gaussian', 'burnin_n': 200, 'draw_n': 200, 'sdev': 0.05}\n",
      "method_name sparse_PCA\n",
      "TCGA\n",
      "{'n_components': 8, 'alpha': 5, 'ridge_alpha': 0.1, 'max_iter': 1000, 'method': 'cd', 'tol': 1e-08}\n",
      "METABRIC\n",
      "{'n_components': 8, 'alpha': 1, 'ridge_alpha': 0.1, 'max_iter': 1000, 'method': 'cd', 'tol': 1e-08}\n"
     ]
    }
   ],
   "source": [
    "# highest PAM50 in each dataset\n",
    "\n",
    "import pandas as pd\n",
    "from methods import NMF, sparse_PCA, moCluster, MOFA2, iClusterPlus\n",
    "\n",
    "for method in [NMF, moCluster, MOFA2, iClusterPlus, sparse_PCA]:\n",
    "    method_name = method.__name__.split('.')[-1]\n",
    "    print('method_name', method_name)\n",
    "    for dataset in ['TCGA', 'METABRIC']:\n",
    "        print(dataset)\n",
    "        \n",
    "        df_meta = pd.read_csv(f'/cosybio/project/hartung/unpast/unpast_real/{method_name}_{dataset}.tsv', sep='\\t', index_col=0)\n",
    "        \n",
    "        df_meta = df_meta.dropna(subset='parameters')\n",
    "        \n",
    "        # remove random state from params\n",
    "        df_meta['parameters'] = df_meta['parameters'].map(lambda x: ';'.join([y for y in x.split(';') if not y.startswith('random_state=')]))\n",
    "        \n",
    "        # merge permutations\n",
    "        df_meta = df_meta.groupby('parameters').mean()\n",
    "        \n",
    "        params = df_meta.sort_values('PAM50', ascending=False).index[0]\n",
    "        d = {}\n",
    "        for x in params.split(';'):\n",
    "            if not len(x):\n",
    "                continue\n",
    "            key, value = x.split('=') \n",
    "            try:\n",
    "                value = eval(value)\n",
    "            except:\n",
    "                pass\n",
    "            d[key] = value\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_name NMF\n",
      "{'k': 3, 'init': 'nndsvd', 'tol': 0.0001, 'transposed': False, 'alpha_W': 0.2, 'alpha_H': 0.0, 'shuffle': True, 'solver': 'cd', 'beta_loss': 'frobenius', 'max_iter': 1000}\n",
      "method_name moCluster\n",
      "{'n_dimensions': 8, 'n_cluster': 8, 'solver': 'svd', 'center': True, 'method': 'globalScore', 'option': 'uniform', 'scale': False, 'k': 0.1}\n",
      "method_name MOFA2\n",
      "{'n_factors': 18, 'n_cluster': 5, 'ard_weights': True, 'ard_factors': False, 'likelihood': 'gaussian', 'spikeslab_weights': True, 'spikeslab_factors': False}\n",
      "method_name iClusterPlus\n",
      "{'lambda_n': 10, 'n_cluster': 4, 'lambda_scale': 1, 'iter_max': 20, 'eps': 0.0001, 'type': 'gaussian', 'burnin_n': 200, 'draw_n': 200, 'sdev': 0.05}\n",
      "method_name sparse_PCA\n",
      "{'n_components': 2, 'alpha': 1, 'ridge_alpha': 0.1, 'max_iter': 1000, 'method': 'cd', 'tol': 1e-08}\n"
     ]
    }
   ],
   "source": [
    "# highest in simulated\n",
    "\n",
    "import pandas as pd\n",
    "from methods import NMF, sparse_PCA, moCluster, MOFA2, iClusterPlus\n",
    "\n",
    "for method in [NMF, moCluster, MOFA2, iClusterPlus, sparse_PCA]:\n",
    "    method_name = method.__name__.split('.')[-1]\n",
    "    print('method_name', method_name)\n",
    "    \n",
    "    df_meta = pd.read_csv(f'/cosybio/project/hartung/unpast/unpast_simluated/{method_name}_ABC.tsv', sep='\\t', index_col=0)\n",
    "    \n",
    "    df_meta = df_meta.dropna(subset='parameters')\n",
    "    \n",
    "    # # remove random state from params\n",
    "    df_meta['parameters'] = df_meta['parameters'].map(lambda x: ';'.join([y for y in x.split(';') if not y.startswith('random_state=')]))\n",
    "    \n",
    "    params = df_meta.groupby('parameters').mean().sort_values(['performance'], ascending=False).index[0]\n",
    "    \n",
    "    d = {}\n",
    "    for x in params.split(';'):\n",
    "        if not len(x):\n",
    "            continue\n",
    "        key, value = x.split('=') \n",
    "        try:\n",
    "            value = eval(value)\n",
    "        except:\n",
    "            pass\n",
    "        d[key] = value\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get results with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import best_parameters\n",
    "import pandas as pd\n",
    "from methods import NMF, sparse_PCA, moCluster, MOFA2, iClusterPlus\n",
    "\n",
    "for method in [NMF, moCluster, MOFA2, iClusterPlus, sparse_PCA]:\n",
    "    method_name = method.__name__.split('.')[-1]\n",
    "    print('method_name', method_name)\n",
    "    \n",
    "    df_meta = pd.read_csv(f'/cosybio/project/hartung/unpast/unpast_real/{method_name}_METABRIC.tsv', sep='\\t', index_col=0)\n",
    "    df_tcga = pd.read_csv(f'/cosybio/project/hartung/unpast/unpast_real/{method_name}_TCGA.tsv', sep='\\t', index_col=0)\n",
    "    \n",
    "    df_meta = df_meta.dropna(subset='parameters')\n",
    "    df_tcga = df_tcga.dropna(subset='parameters')\n",
    "    \n",
    "    # remove random state from params\n",
    "    df_meta['parameters'] = df_meta['parameters'].map(lambda x: ';'.join([y for y in x.split(';') if not y.startswith('random_state=')]))\n",
    "    df_tcga['parameters'] = df_tcga['parameters'].map(lambda x: ';'.join([y for y in x.split(';') if not y.startswith('random_state=')]))\n",
    "    \n",
    "    # merge permutations\n",
    "    df_meta = df_meta.groupby('parameters').mean()\n",
    "    df_tcga = df_tcga.groupby('parameters').mean()\n",
    "    \n",
    "    df_meta = df_meta.sort_values('PAM50', ascending=False)\n",
    "    df_meta['rank'] = list(range(len(df_meta.index)))\n",
    "    \n",
    "    df_tcga = df_tcga.sort_values('PAM50', ascending=False)\n",
    "    df_tcga['rank'] = list(range(len(df_tcga.index)))\n",
    "    \n",
    "    df = pd.concat([df_tcga, df_meta]).groupby('parameters').sum()\n",
    "    \n",
    "    params = df.sort_values('rank', ascending=True).index[0]\n",
    "    d = {y[0]: y[1] for y in [x.split('=') for x in params.split(';') if len(x)]}\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
