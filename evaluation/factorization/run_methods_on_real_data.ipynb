{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb44572",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Set number of cores for parallel computation\n",
    "# For just reading output files and creating summary, use 1 kernel\n",
    "KERNEL = 1\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys,os\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from methods import NMF, sparse_PCA, moCluster, MOFA2, iClusterPlus\n",
    "\n",
    "from methods.utils import interpret_results, resultsHandler, miscellaneous\n",
    "\n",
    "from pathlib import Path\n",
    "import multiprocessing as mp\n",
    "\n",
    "from utils.eval import compare_gene_clusters, make_ref_groups, calculate_perfromance\n",
    "\n",
    "\n",
    "file_metabric_annotation = '/local/DESMOND2_data/v6/preprocessed_v6/METABRIC_1904.annotation_v6.tsv'\n",
    "file_metabric_expression = '/local/DESMOND2_data/v6/preprocessed_v6/METABRIC_1904_17Kgenes.log2_exprs_z_v6.tsv'\n",
    "file_metabric_subtypes = '/local/DESMOND2_data/v6/preprocessed_v6/METABRIC_1904_17Kgenes.subtypes_and_signatures_v6.tsv'\n",
    "file_tcga_annotation = '/local/DESMOND2_data/v6/preprocessed_v6/TCGA-BRCA_1079.Xena_TCGA_PanCan.annotation_v6.tsv'\n",
    "file_tcga_expression = '/local/DESMOND2_data/v6/preprocessed_v6/TCGA-BRCA_1079_17Kgenes.Xena_TCGA_PanCan.log2_exprs_z_v6.tsv'\n",
    "file_tcga_subtypes = '/local/DESMOND2_data/v6/preprocessed_v6/TCGA-BRCA_1079_17Kgenes.Xena_TCGA_PanCan.subtypes_and_signatures_v6.tsv'\n",
    "file_gene_mapping = '/local/DESMOND2_data/v6/preprocessed_v6/gene_id_mapping.tsv'\n",
    "\n",
    "# out_dir = '/home/hartung/data/preprocessed_v6/results's\n",
    "out_dir = '/cosybio/project/hartung/unpast/unpast_real'\n",
    "\n",
    "basename_t = \"TCGA\"\n",
    "basename_m = \"METABRIC\"\n",
    "\n",
    "m_subtypes = pd.read_csv(file_metabric_subtypes,sep = \"\\t\",index_col=0)\n",
    "m_annotation = pd.read_csv(file_metabric_annotation,sep = \"\\t\",index_col=0)\n",
    "\n",
    "t_subtypes = pd.read_csv(file_tcga_subtypes,sep = \"\\t\",index_col=0)\n",
    "t_annotation = pd.read_csv(file_tcga_annotation,sep = \"\\t\",index_col=0)\n",
    "\n",
    "\n",
    "exprs_t= pd.read_csv(file_tcga_expression,sep = \"\\t\",index_col=0)\n",
    "exprs_t[exprs_t>3] = 3\n",
    "exprs_t[exprs_t<-3] = -3\n",
    "\n",
    "exprs_m= pd.read_csv(file_metabric_expression,sep = \"\\t\",index_col=0)\n",
    "exprs_m[exprs_m>3] = 3\n",
    "exprs_m[exprs_m<-3] = -3\n",
    "\n",
    "known_groups_t, freqs_t = make_ref_groups(t_subtypes, t_annotation,exprs_t)\n",
    "known_groups_m, freqs_m = make_ref_groups(m_subtypes, m_annotation,exprs_m)\n",
    "\n",
    "n_samples_m = len(exprs_m.columns)\n",
    "n_samples_t = len(exprs_t.columns)\n",
    "\n",
    "        \n",
    "METHODS = [sparse_PCA] # [NMF, moCluster, MOFA2, iClusterPlus, ]\n",
    "for METHOD in METHODS:\n",
    "    method_name = METHOD.__name__.split('.')[-1]\n",
    "    print('method_name', method_name)\n",
    "\n",
    "    #### Preparation\n",
    "    # METABRIC\n",
    "    file_path_m = file_metabric_expression\n",
    "    output_path_m = os.path.join(out_dir, basename_m, method_name)\n",
    "    ground_truth_file_m = file_metabric_annotation\n",
    "    combinations_m = METHOD.generate_arg_list(file_path_m, output_path_m, ground_truth_file_m)\n",
    "    # TCGA\n",
    "    file_path_t = file_tcga_expression\n",
    "    output_path_t = os.path.join(out_dir, basename_t, method_name)\n",
    "    ground_truth_file_t = file_tcga_annotation\n",
    "    combinations_t = METHOD.generate_arg_list(file_path_t, output_path_t, ground_truth_file_t)\n",
    "\n",
    "\n",
    "    #### Compute in parallel\n",
    "    # Option to compute the results in parallel, methods will store results\n",
    "    # Follow up with executing the 'Run' below to read existing results and evaluate\n",
    "    if KERNEL > 1:\n",
    "        with mp.Pool(KERNEL) as pool:\n",
    "            pool.map(METHOD.run_real, combinations_m + combinations_t)\n",
    "\n",
    "    #### Run\n",
    "    # Methods will compute results or read existing results\n",
    "    # sanity check\n",
    "    assert len(combinations_m) == len(combinations_t)\n",
    "    subt_t = []\n",
    "    subt_m = []\n",
    "    best_matches_m_list = []\n",
    "    best_matches_t_list = []\n",
    "    clustering_similarities = []\n",
    "    for comb_m, comb_t in zip(combinations_m, combinations_t):\n",
    "        result_m, runtime_m = METHOD.run_real(comb_m, is_terminated=True)\n",
    "        result_t, runtime_t = METHOD.run_real(comb_t, is_terminated=True)\n",
    "        \n",
    "        t_failed = False\n",
    "        m_failed = False\n",
    "        \n",
    "        # Please exclude too small cluster with <5 samples and too large clusters > all but 5 samples before performance evaluation\n",
    "        if result_m is not False:\n",
    "            result_m = result_m[(result_m['n_samples'] >= 5) & (result_m['n_samples'] <= (n_samples_m-5))]\n",
    "        if result_t is not False:\n",
    "            result_t = result_t[(result_t['n_samples'] >= 5) & (result_t['n_samples'] <= (n_samples_t-5))]\n",
    "\n",
    "        try:\n",
    "            performance_m, best_matches_m = calculate_perfromance(result_m, known_groups_m, set(exprs_m.columns.values), min_n_samples=5)\n",
    "            performance_m = performance_m.to_dict()\n",
    "            best_matches_m = best_matches_m.to_dict()\n",
    "            \n",
    "            performance_m.update({'parameters': miscellaneous.combination_to_string(comb_m), 'run': comb_m['random_state']})\n",
    "            performance_m['time'] = runtime_m\n",
    "        except (ZeroDivisionError, AttributeError):\n",
    "            m_failed = True\n",
    "            performance_m = {}\n",
    "            best_matches_m = {}\n",
    "        subt_m.append(performance_m)\n",
    "        best_matches_m_list.append(best_matches_m)\n",
    "\n",
    "        try:\n",
    "            performance_t, best_matches_t = calculate_perfromance(result_t, known_groups_t,\n",
    "                                                    set(exprs_t.columns.values))\n",
    "            performance_t = performance_t.to_dict()\n",
    "            best_matches_t = best_matches_t.to_dict()\n",
    "            \n",
    "            performance_t.update({'parameters': miscellaneous.combination_to_string(comb_t), 'run': comb_t['random_state']})\n",
    "            performance_t['time'] = runtime_t\n",
    "        except (ZeroDivisionError, AttributeError):\n",
    "            t_failed= True\n",
    "            performance_t = {}\n",
    "            best_matches_t = {}\n",
    "        subt_t.append(performance_t)\n",
    "        best_matches_t_list.append(best_matches_t)\n",
    "        \n",
    "        # compare clustering results - only if gene sets are defined for each cluster\n",
    "        clust_sim = {}\n",
    "        if not (t_failed or m_failed):\n",
    "            N = exprs_m.shape[0]\n",
    "            try:\n",
    "                if isinstance(result_t['genes'][0], str):\n",
    "                    result_t['genes'] = result_t['genes'].map(eval)\n",
    "                    result_t['genes'] = result_t['genes'].map(set)\n",
    "                if isinstance(result_m['genes'][0], str):\n",
    "                    result_m['genes'] = result_m['genes'].map(eval)\n",
    "                    result_m['genes'] = result_m['genes'].map(set)\n",
    "                clust_sim, bm, bm2 = compare_gene_clusters(result_t, result_m, N)\n",
    "            except (ZeroDivisionError, KeyError) as e:\n",
    "                # print('Error')\n",
    "                # print(e)\n",
    "                # 'n_shared' is not defined because gene clusters empty\n",
    "                pass     \n",
    "        # comb_m and comb_t have same parameters besides input file\n",
    "        clust_sim.update(comb_m)\n",
    "        clustering_similarities.append(clust_sim)\n",
    "\n",
    "    # save results\n",
    "    pd.DataFrame.from_records(subt_m).to_csv(os.path.join(out_dir, f'{method_name}_METABRIC.tsv'), sep=\"\\t\")    \n",
    "    pd.DataFrame.from_records(subt_t).to_csv(os.path.join(out_dir, f'{method_name}_TCGA.tsv'), sep=\"\\t\")\n",
    "    pd.DataFrame.from_records(clustering_similarities).to_csv(os.path.join(out_dir, f'{method_name}_similarities.tsv'), sep=\"\\t\")\n",
    "    \n",
    "    pd.DataFrame.from_records(best_matches_m_list).to_csv(os.path.join(out_dir, f'{method_name}_METABRIC_best_matches.tsv'), sep=\"\\t\")    \n",
    "    pd.DataFrame.from_records(best_matches_t_list).to_csv(os.path.join(out_dir, f'{method_name}_TCGA_best_matches.tsv'), sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93343975",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
