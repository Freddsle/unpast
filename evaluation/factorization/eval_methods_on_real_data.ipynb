{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys,os\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from utils.eval import find_best_matches, generate_exprs\n",
    "\n",
    "from methods import NMF, PCA, sparse_PCA, moCluster, MOFA2, iClusterPlus\n",
    "\n",
    "from methods.utils import interpret_results, resultsHandler\n",
    "\n",
    "from pathlib import Path\n",
    "import multiprocessing as mp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys,os\n",
    "import random\n",
    "import copy\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from utils.method import read_bic_table\n",
    "\n",
    "from utils.eval import find_best_matches, make_known_groups, make_ref_groups\n",
    "from utils.eval import calculate_perfromance, compare_gene_clusters\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "\n",
    "def read_nmf_results(comb, exprs):\n",
    "    from methods.NMF import interpret_results, resultsHandler\n",
    "\n",
    "    p = comb['output_path']\n",
    "\n",
    "    path_w = os.path.join(p, 'W.csv')\n",
    "    path_h = os.path.join(p, 'H.csv')\n",
    "\n",
    "    df_w = pd.read_csv(path_w, index_col=0)\n",
    "    df_h = pd.read_csv(path_h, index_col=0)\n",
    "    \n",
    "    result = interpret_results.format_sklearn_output(df_h.values, len(df_h.index), exprs.columns, False)\n",
    "    result_genes = interpret_results.format_sklearn_output(df_w.values, len(df_w.columns), exprs.index, True)\n",
    "    result['genes'] = result_genes['samples']\n",
    "    result['n_genes'] = result_genes['n_samples']\n",
    "    return result, resultsHandler.read_runtime(comb[\"output_path\"])\n",
    "\n",
    "\n",
    "gene_sets_are_defined = ['NMF', 'sparse_PCA', ]\n",
    "\n",
    "classifications={\"Intrinsic\":[\"Luminal\",\"Basal\",\"Her2\",\"Normal\",\"Claudin-low\"],\n",
    "                \"SCMOD2\":[\"ER-/HER2-\",\"ER+/HER2- Low Prolif\",\"ER+/HER2- High Prolif\",\"HER2+\"],\n",
    "                \"IHC\":[\"IHC_TNBC\",\"IHC_ER\",\"IHC_HER2\",\"IHC_PR\"]}\n",
    "\n",
    "file_metabric_annotation = '/local/DESMOND2_data/v6/preprocessed_v6/METABRIC_1904.annotation_v6.tsv'\n",
    "file_metabric_expression = '/local/DESMOND2_data/v6/preprocessed_v6/METABRIC_1904_17Kgenes.log2_exprs_z_v6.tsv'\n",
    "file_metabric_subtypes = '/local/DESMOND2_data/v6/preprocessed_v6/METABRIC_1904_17Kgenes.subtypes_and_signatures_v6.tsv'\n",
    "file_tcga_annotation = '/local/DESMOND2_data/v6/preprocessed_v6/TCGA-BRCA_1079.Xena_TCGA_PanCan.annotation_v6.tsv'\n",
    "file_tcga_expression = '/local/DESMOND2_data/v6/preprocessed_v6/TCGA-BRCA_1079_17Kgenes.Xena_TCGA_PanCan.log2_exprs_z_v6.tsv'\n",
    "file_tcga_subtypes = '/local/DESMOND2_data/v6/preprocessed_v6/TCGA-BRCA_1079_17Kgenes.Xena_TCGA_PanCan.subtypes_and_signatures_v6.tsv'\n",
    "file_gene_mapping = '/local/DESMOND2_data/v6/preprocessed_v6/gene_id_mapping.tsv'\n",
    "\n",
    "out_dir = '/cosybio/project/hartung/unpast/unpast_real'\n",
    "\n",
    "basename_t = \"TCGA\"\n",
    "basename_m = \"METABRIC\" \n",
    "\n",
    "m_subtypes = pd.read_csv(file_metabric_subtypes,sep = \"\\t\",index_col=0)\n",
    "m_annotation = pd.read_csv(file_metabric_annotation,sep = \"\\t\",index_col=0)\n",
    "\n",
    "t_subtypes = pd.read_csv(file_tcga_subtypes,sep = \"\\t\",index_col=0)\n",
    "t_annotation = pd.read_csv(file_tcga_annotation,sep = \"\\t\",index_col=0)\n",
    "\n",
    "\n",
    "exprs_t= pd.read_csv(file_tcga_expression,sep = \"\\t\",index_col=0)\n",
    "exprs_t[exprs_t>3] = 3\n",
    "exprs_t[exprs_t<-3] = -3\n",
    "\n",
    "exprs_m= pd.read_csv(file_metabric_expression,sep = \"\\t\",index_col=0)\n",
    "exprs_m[exprs_m>3] = 3\n",
    "exprs_m[exprs_m<-3] = -3\n",
    "\n",
    "known_groups_t, freqs_t = make_ref_groups(t_subtypes, t_annotation,exprs_t)\n",
    "known_groups_m, freqs_m = make_ref_groups(m_subtypes, m_annotation,exprs_m)\n",
    "\n",
    "result_t = None\n",
    "result_m = None\n",
    "\n",
    "def eval_method(METHOD):\n",
    "    global result_t\n",
    "    global result_m\n",
    "    \n",
    "    method_name = METHOD.__name__.split('.')[-1]\n",
    "    print('method_name:', method_name)\n",
    "\n",
    "\n",
    "    #### Preparation\n",
    "    # METABRIC\n",
    "    file_path_m = file_metabric_expression\n",
    "    output_path_m = os.path.join(out_dir, basename_m, method_name)\n",
    "    ground_truth_file_m = file_metabric_annotation\n",
    "    combinations_m = METHOD.generate_arg_list(file_path_m, output_path_m, ground_truth_file_m)\n",
    "    # TCGA\n",
    "    file_path_t = file_tcga_expression\n",
    "    output_path_t = os.path.join(out_dir, basename_t, method_name)\n",
    "    ground_truth_file_t = file_tcga_annotation\n",
    "    combinations_t = METHOD.generate_arg_list(file_path_t, output_path_t, ground_truth_file_t)\n",
    "\n",
    "\n",
    "    #### Run\n",
    "    # Methods will compute results or read existing results\n",
    "    # sanity check\n",
    "    assert len(combinations_m) == len(combinations_t)\n",
    "    \n",
    "    print(f'{len(combinations_m)} combinations.')\n",
    "    subt_t = []\n",
    "    subt_m = [] \n",
    "    clustering_similarities = []\n",
    "    for _iteration, (comb_m, comb_t) in enumerate(zip(combinations_m, combinations_t)):\n",
    "\n",
    "        \n",
    "        if method_name == 'NMF':\n",
    "            try:\n",
    "                result_m, runtime_m = read_nmf_results(comb_m, exprs_m)\n",
    "                result_t, runtime_t = read_nmf_results(comb_t, exprs_t)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "        else:\n",
    "            result_m, runtime_m = METHOD.run_real(comb_m, is_terminated=True)\n",
    "            result_t, runtime_t = METHOD.run_real(comb_t, is_terminated=True)\n",
    "            \n",
    "        if 'genes' in result_m and result_m is not False and type(result_m['genes'][0]) is str:\n",
    "            result_m['genes'] = result_m['genes'].map(eval).map(set)\n",
    "        if 'genes' in result_t and result_t is not False and type(result_t['genes'][0]) is str:\n",
    "            result_t['genes'] = result_t['genes'].map(eval).map(set)\n",
    "\n",
    "        t_failed = False\n",
    "        m_failed = False\n",
    "\n",
    "        try:\n",
    "            # in case no result file\n",
    "            if result_m is False:\n",
    "                # raise Exception\n",
    "                continue\n",
    "              \n",
    "            performance_m = calculate_perfromance(result_m, known_groups_m,\n",
    "                                                    freqs_m, set(exprs_m.columns.values),\n",
    "                                                    classifications=classifications)\n",
    "            performance_m.update({'parameters': comb_m['output_path'], 'run': comb_m['random_state']})\n",
    "            performance_m['time'] = runtime_m\n",
    "        except ZeroDivisionError:\n",
    "            performance_m = {}\n",
    "            m_failed = True\n",
    "        subt_m.append(performance_m)\n",
    "\n",
    "        try:\n",
    "            # in case no result file\n",
    "            if result_t is False:\n",
    "                # raise Exception\n",
    "                continue\n",
    "            \n",
    "            performance_t = calculate_perfromance(result_t, known_groups_t,\n",
    "                                                    freqs_t, set(exprs_t.columns.values),\n",
    "                                                    classifications=classifications)\n",
    "            performance_t.update({'parameters': comb_t['output_path'], 'run': comb_t['random_state']})\n",
    "            performance_t['time'] = runtime_t\n",
    "        except ZeroDivisionError:\n",
    "            performance_t = {}\n",
    "            t_failed = True\n",
    "        subt_t.append(performance_t)\n",
    "        \n",
    "        \n",
    "        if method_name in gene_sets_are_defined:\n",
    "            # compare clustering results - only if gene sets are defined for each cluster\n",
    "            clust_sim = {}\n",
    "            if not (t_failed or m_failed):\n",
    "                N = exprs_m.shape[0]\n",
    "                try:\n",
    "                    if len(result_t[(result_t['n_genes'] > 0) & (result_t['n_samples'] > 0)]) == 0 or len(result_m[(result_m['n_genes'] > 0) & (result_m['n_samples'] > 0)]) == 0:\n",
    "                        raise KeyError\n",
    "                    \n",
    "                    clust_sim, bm, bm2 = compare_gene_clusters(result_t, result_m, N)  \n",
    "                    # print('Wuhu')\n",
    "                    \n",
    "                except KeyError:\n",
    "                    # 'n_shared' is not defined because gene clusters empty\n",
    "                    pass     \n",
    "            # comb_m and comb_t have same parameters besides input file\n",
    "            clust_sim.update(comb_m)\n",
    "            clustering_similarities.append(clust_sim)\n",
    "            \n",
    "        if not _iteration % 100:\n",
    "            print('Iteration:', _iteration)\n",
    "\n",
    "            # save results\n",
    "            pd.DataFrame.from_records(subt_m).to_csv(os.path.join(out_dir, basename_m, method_name, f'{method_name}_METABRIC.tsv'), sep=\"\\t\")    \n",
    "            pd.DataFrame.from_records(subt_t).to_csv(os.path.join(out_dir, basename_t, method_name, f'{method_name}_TCGA.tsv'), sep=\"\\t\")\n",
    "            \n",
    "            pd.DataFrame.from_records(clustering_similarities).to_csv(os.path.join(out_dir, basename_m, method_name, f'{method_name}_similarities.tsv'), sep = \"\\t\")\n",
    "            pd.DataFrame.from_records(subt_t).to_csv(os.path.join(out_dir, basename_m, method_name, f'{method_name}_TCGA_similarities.tsv'),sep = \"\\t\")\n",
    "            pd.DataFrame.from_records(subt_m).to_csv(os.path.join(out_dir, basename_m, method_name, f'{method_name}_METABRIC_similarities.tsv'),sep = \"\\t\")\n",
    "    \n",
    "    print(f'found {len(subt_m)} combinations for metabric')\n",
    "    print(f'found {len(subt_t)} combinations for tcga')\n",
    "    \n",
    "    # save results\n",
    "    pd.DataFrame.from_records(subt_m).to_csv(os.path.join(out_dir, basename_m, method_name, f'{method_name}_METABRIC.tsv'), sep=\"\\t\")    \n",
    "    pd.DataFrame.from_records(subt_t).to_csv(os.path.join(out_dir, basename_t, method_name, f'{method_name}_TCGA.tsv'), sep=\"\\t\")\n",
    "    \n",
    "    pd.DataFrame.from_records(clustering_similarities).to_csv(os.path.join(out_dir, basename_m, method_name, f'{method_name}_similarities.tsv'), sep = \"\\t\")\n",
    "    pd.DataFrame.from_records(subt_t).to_csv(os.path.join(out_dir, basename_m, method_name, f'{method_name}_TCGA_similarities.tsv'),sep = \"\\t\")\n",
    "    pd.DataFrame.from_records(subt_m).to_csv(os.path.join(out_dir, basename_m, method_name, f'{method_name}_METABRIC_similarities.tsv'),sep = \"\\t\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METHODS = [NMF, sparse_PCA, moCluster, MOFA2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_name: MOFA2\n",
      "1900 combinations.\n",
      "Iteration: 0\n",
      "Iteration: 1000\n",
      "found 1900 combinations for metabric\n",
      "found 1900 combinations for tcga\n"
     ]
    }
   ],
   "source": [
    "eval_method(MOFA2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_name: moCluster\n",
      "4560 combinations.\n",
      "Iteration: 0\n",
      "Iteration: 1000\n",
      "Iteration: 2000\n",
      "Iteration: 3000\n",
      "Iteration: 4000\n",
      "found 4560 combinations for metabric\n",
      "found 4560 combinations for tcga\n"
     ]
    }
   ],
   "source": [
    "eval_method(moCluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_name: NMF\n",
      "30000 combinations.\n",
      "Iteration: 0\n",
      "Iteration: 100\n",
      "Iteration: 200\n",
      "Iteration: 300\n",
      "Iteration: 400\n",
      "Iteration: 500\n",
      "Iteration: 600\n",
      "Iteration: 700\n",
      "Iteration: 800\n",
      "Iteration: 900\n",
      "Iteration: 1000\n",
      "Iteration: 1100\n",
      "Iteration: 1200\n",
      "Iteration: 1300\n",
      "Iteration: 1400\n",
      "Iteration: 1500\n",
      "Iteration: 1600\n",
      "Iteration: 1700\n",
      "Iteration: 1800\n",
      "Iteration: 1900\n",
      "Iteration: 2000\n",
      "Iteration: 2100\n",
      "Iteration: 2200\n",
      "Iteration: 2300\n",
      "Iteration: 2400\n",
      "Iteration: 2500\n",
      "Iteration: 2600\n",
      "Iteration: 2700\n",
      "Iteration: 2800\n",
      "Iteration: 2900\n",
      "Iteration: 3000\n",
      "Iteration: 3100\n",
      "Iteration: 3200\n",
      "Iteration: 3300\n",
      "Iteration: 3400\n",
      "Iteration: 3500\n",
      "Iteration: 3600\n",
      "Iteration: 3700\n",
      "Iteration: 3800\n",
      "Iteration: 3900\n",
      "Iteration: 4000\n",
      "Iteration: 4100\n",
      "Iteration: 4200\n",
      "Iteration: 4300\n",
      "Iteration: 4400\n",
      "Iteration: 4500\n",
      "Iteration: 4600\n",
      "Iteration: 4700\n",
      "Iteration: 4800\n",
      "Iteration: 4900\n",
      "Iteration: 5000\n",
      "Iteration: 5100\n",
      "Iteration: 5200\n",
      "Iteration: 5300\n",
      "Iteration: 5400\n",
      "Iteration: 5500\n",
      "Iteration: 5600\n",
      "Iteration: 5700\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/bba1401/Projects/unpast/DESMOND2/evaluation/factorization/eval_methods_on_real_data.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bllaima.zbh.uni-hamburg.de/home/bba1401/Projects/unpast/DESMOND2/evaluation/factorization/eval_methods_on_real_data.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m eval_method(NMF)\n",
      "\u001b[1;32m/home/bba1401/Projects/unpast/DESMOND2/evaluation/factorization/eval_methods_on_real_data.ipynb Cell 5\u001b[0m in \u001b[0;36meval_method\u001b[0;34m(METHOD)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bllaima.zbh.uni-hamburg.de/home/bba1401/Projects/unpast/DESMOND2/evaluation/factorization/eval_methods_on_real_data.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=131'>132</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bllaima.zbh.uni-hamburg.de/home/bba1401/Projects/unpast/DESMOND2/evaluation/factorization/eval_methods_on_real_data.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=132'>133</a>\u001b[0m     result_m, runtime_m \u001b[39m=\u001b[39m read_nmf_results(comb_m, exprs_m)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bllaima.zbh.uni-hamburg.de/home/bba1401/Projects/unpast/DESMOND2/evaluation/factorization/eval_methods_on_real_data.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=133'>134</a>\u001b[0m     result_t, runtime_t \u001b[39m=\u001b[39m read_nmf_results(comb_t, exprs_t)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bllaima.zbh.uni-hamburg.de/home/bba1401/Projects/unpast/DESMOND2/evaluation/factorization/eval_methods_on_real_data.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=134'>135</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bllaima.zbh.uni-hamburg.de/home/bba1401/Projects/unpast/DESMOND2/evaluation/factorization/eval_methods_on_real_data.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=135'>136</a>\u001b[0m     \u001b[39mprint\u001b[39m(e)\n",
      "\u001b[1;32m/home/bba1401/Projects/unpast/DESMOND2/evaluation/factorization/eval_methods_on_real_data.ipynb Cell 5\u001b[0m in \u001b[0;36mread_nmf_results\u001b[0;34m(comb, exprs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bllaima.zbh.uni-hamburg.de/home/bba1401/Projects/unpast/DESMOND2/evaluation/factorization/eval_methods_on_real_data.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m path_w \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(p, \u001b[39m'\u001b[39m\u001b[39mW.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bllaima.zbh.uni-hamburg.de/home/bba1401/Projects/unpast/DESMOND2/evaluation/factorization/eval_methods_on_real_data.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m path_h \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(p, \u001b[39m'\u001b[39m\u001b[39mH.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bllaima.zbh.uni-hamburg.de/home/bba1401/Projects/unpast/DESMOND2/evaluation/factorization/eval_methods_on_real_data.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m df_w \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(path_w, index_col\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bllaima.zbh.uni-hamburg.de/home/bba1401/Projects/unpast/DESMOND2/evaluation/factorization/eval_methods_on_real_data.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m df_h \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(path_h, index_col\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bllaima.zbh.uni-hamburg.de/home/bba1401/Projects/unpast/DESMOND2/evaluation/factorization/eval_methods_on_real_data.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m result \u001b[39m=\u001b[39m interpret_results\u001b[39m.\u001b[39mformat_sklearn_output(df_h\u001b[39m.\u001b[39mvalues, \u001b[39mlen\u001b[39m(df_h\u001b[39m.\u001b[39mindex), exprs\u001b[39m.\u001b[39mcolumns, \u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/encore2/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/encore2/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/encore2/lib/python3.8/site-packages/pandas/io/parsers/readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    580\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 581\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m~/anaconda3/envs/encore2/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1254\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1252\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1253\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1254\u001b[0m     index, columns, col_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(nrows)\n\u001b[1;32m   1255\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1256\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/encore2/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:225\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 225\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[1;32m    226\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    227\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/anaconda3/envs/encore2/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:805\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/encore2/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:883\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/encore2/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1026\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/encore2/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1072\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/encore2/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1147\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/encore2/lib/python3.8/site-packages/pandas/core/dtypes/common.py:1429\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[39m# Note: if other EA dtypes are ever held in HybridBlock, exclude those\u001b[39;00m\n\u001b[1;32m   1421\u001b[0m     \u001b[39m#  here too.\u001b[39;00m\n\u001b[1;32m   1422\u001b[0m     \u001b[39m# NB: need to check DatetimeTZDtype and not is_datetime64tz_dtype\u001b[39;00m\n\u001b[1;32m   1423\u001b[0m     \u001b[39m#  to exclude ArrowTimestampUSDtype\u001b[39;00m\n\u001b[1;32m   1424\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, ExtensionDtype) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m   1425\u001b[0m         dtype, (DatetimeTZDtype, PeriodDtype)\n\u001b[1;32m   1426\u001b[0m     )\n\u001b[0;32m-> 1429\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_extension_array_dtype\u001b[39m(arr_or_dtype) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m   1430\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1431\u001b[0m \u001b[39m    Check if an object is a pandas extension array type.\u001b[39;00m\n\u001b[1;32m   1432\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1472\u001b[0m \u001b[39m    False\u001b[39;00m\n\u001b[1;32m   1473\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1474\u001b[0m     dtype \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(arr_or_dtype, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, arr_or_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eval_method(NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_name: sparse_PCA\n",
      "600 combinations.\n",
      "Iteration: 0\n",
      "Iteration: 100\n",
      "Iteration: 200\n",
      "Iteration: 300\n",
      "Iteration: 400\n",
      "Iteration: 500\n",
      "found 575 combinations for metabric\n",
      "found 575 combinations for tcga\n"
     ]
    }
   ],
   "source": [
    "eval_method(sparse_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_name: iClusterPlus\n",
      "380 combinations.\n",
      "Iteration: 0\n",
      "Iteration: 100\n",
      "Iteration: 200\n",
      "Iteration: 300\n",
      "found 380 combinations for metabric\n",
      "found 380 combinations for tcga\n"
     ]
    }
   ],
   "source": [
    "eval_method(iClusterPlus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>samples</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{TCGA-B6-A1KC-01, TCGA-E9-A1RD-01, TCGA-EW-A1I...</td>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{TCGA-GM-A5PX-01, TCGA-E2-A572-01, TCGA-AC-A62...</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             samples  n_samples\n",
       "1  {TCGA-B6-A1KC-01, TCGA-E9-A1RD-01, TCGA-EW-A1I...        712\n",
       "2  {TCGA-GM-A5PX-01, TCGA-E2-A572-01, TCGA-AC-A62...        367"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encore2",
   "language": "python",
   "name": "encore2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
